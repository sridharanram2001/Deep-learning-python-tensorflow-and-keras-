{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"C:/Users/admin/Downloads/TF_2_Notebooks_and_Data/DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 2s 18ms/sample - loss: 1.0130 - accuracy: 0.4000 - val_loss: 1.0686 - val_accuracy: 0.3000\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 1.0111 - accuracy: 0.4167 - val_loss: 1.0664 - val_accuracy: 0.3000\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 1.0092 - accuracy: 0.4333 - val_loss: 1.0643 - val_accuracy: 0.3000\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0073 - accuracy: 0.4583 - val_loss: 1.0622 - val_accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 1.0054 - accuracy: 0.4750 - val_loss: 1.0601 - val_accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 1.0035 - accuracy: 0.4750 - val_loss: 1.0580 - val_accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0016 - accuracy: 0.4833 - val_loss: 1.0560 - val_accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.9998 - accuracy: 0.5000 - val_loss: 1.0542 - val_accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.9980 - accuracy: 0.5083 - val_loss: 1.0524 - val_accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.9961 - accuracy: 0.5083 - val_loss: 1.0506 - val_accuracy: 0.4000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.9943 - accuracy: 0.5167 - val_loss: 1.0487 - val_accuracy: 0.4333\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.9926 - accuracy: 0.5167 - val_loss: 1.0470 - val_accuracy: 0.4333\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.9907 - accuracy: 0.5500 - val_loss: 1.0453 - val_accuracy: 0.4333\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.9889 - accuracy: 0.5750 - val_loss: 1.0436 - val_accuracy: 0.4333\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.9870 - accuracy: 0.5833 - val_loss: 1.0418 - val_accuracy: 0.4667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9852 - accuracy: 0.5833 - val_loss: 1.0401 - val_accuracy: 0.4667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.9832 - accuracy: 0.5917 - val_loss: 1.0383 - val_accuracy: 0.4667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.9810 - accuracy: 0.6083 - val_loss: 1.0365 - val_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.9788 - accuracy: 0.6083 - val_loss: 1.0349 - val_accuracy: 0.5000\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 0.9761 - accuracy: 0.6250 - val_loss: 1.0331 - val_accuracy: 0.5000\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.9732 - accuracy: 0.6250 - val_loss: 1.0312 - val_accuracy: 0.5000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9697 - accuracy: 0.6333 - val_loss: 1.0290 - val_accuracy: 0.5000\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.9663 - accuracy: 0.6333 - val_loss: 1.0269 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.9630 - accuracy: 0.6333 - val_loss: 1.0251 - val_accuracy: 0.5000\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.9600 - accuracy: 0.6333 - val_loss: 1.0238 - val_accuracy: 0.5000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.9568 - accuracy: 0.6333 - val_loss: 1.0221 - val_accuracy: 0.5000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.9539 - accuracy: 0.6417 - val_loss: 1.0201 - val_accuracy: 0.5000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.9512 - accuracy: 0.6500 - val_loss: 1.0183 - val_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.9487 - accuracy: 0.6583 - val_loss: 1.0164 - val_accuracy: 0.5333\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.9459 - accuracy: 0.6583 - val_loss: 1.0144 - val_accuracy: 0.5333\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.9434 - accuracy: 0.6583 - val_loss: 1.0122 - val_accuracy: 0.5667\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.9410 - accuracy: 0.6583 - val_loss: 1.0101 - val_accuracy: 0.5667\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.9385 - accuracy: 0.6583 - val_loss: 1.0078 - val_accuracy: 0.5667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.9361 - accuracy: 0.6583 - val_loss: 1.0058 - val_accuracy: 0.5667\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.9336 - accuracy: 0.6667 - val_loss: 1.0037 - val_accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.9311 - accuracy: 0.6750 - val_loss: 1.0014 - val_accuracy: 0.5667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.9286 - accuracy: 0.6833 - val_loss: 0.9990 - val_accuracy: 0.5667\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9261 - accuracy: 0.6833 - val_loss: 0.9964 - val_accuracy: 0.5667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9237 - accuracy: 0.6833 - val_loss: 0.9942 - val_accuracy: 0.5667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.9211 - accuracy: 0.6833 - val_loss: 0.9918 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.9186 - accuracy: 0.6833 - val_loss: 0.9894 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.9160 - accuracy: 0.6833 - val_loss: 0.9871 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 0.9135 - accuracy: 0.6833 - val_loss: 0.9850 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.9108 - accuracy: 0.6833 - val_loss: 0.9828 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 211us/sample - loss: 0.9082 - accuracy: 0.6833 - val_loss: 0.9807 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.9056 - accuracy: 0.6833 - val_loss: 0.9785 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.9029 - accuracy: 0.6833 - val_loss: 0.9762 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.9004 - accuracy: 0.6833 - val_loss: 0.9742 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.8977 - accuracy: 0.6833 - val_loss: 0.9719 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.8950 - accuracy: 0.6833 - val_loss: 0.9696 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.8925 - accuracy: 0.6833 - val_loss: 0.9673 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.8899 - accuracy: 0.6833 - val_loss: 0.9651 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.8873 - accuracy: 0.6833 - val_loss: 0.9627 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.8847 - accuracy: 0.6833 - val_loss: 0.9607 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.8821 - accuracy: 0.6833 - val_loss: 0.9586 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 240us/sample - loss: 0.8797 - accuracy: 0.6833 - val_loss: 0.9567 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.8770 - accuracy: 0.6833 - val_loss: 0.9545 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.8745 - accuracy: 0.6833 - val_loss: 0.9520 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.8719 - accuracy: 0.6833 - val_loss: 0.9496 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8694 - accuracy: 0.6833 - val_loss: 0.9472 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.8669 - accuracy: 0.6833 - val_loss: 0.9448 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.8644 - accuracy: 0.6833 - val_loss: 0.9425 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 0.8618 - accuracy: 0.6833 - val_loss: 0.9401 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.8594 - accuracy: 0.6833 - val_loss: 0.9376 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.8568 - accuracy: 0.6833 - val_loss: 0.9352 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.8544 - accuracy: 0.6833 - val_loss: 0.9328 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.8518 - accuracy: 0.6833 - val_loss: 0.9303 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.8494 - accuracy: 0.6833 - val_loss: 0.9277 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.8469 - accuracy: 0.6833 - val_loss: 0.9252 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.8445 - accuracy: 0.6833 - val_loss: 0.9228 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8420 - accuracy: 0.6833 - val_loss: 0.9205 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.8397 - accuracy: 0.6833 - val_loss: 0.9184 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.8372 - accuracy: 0.6833 - val_loss: 0.9158 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.8348 - accuracy: 0.6833 - val_loss: 0.9135 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.8324 - accuracy: 0.6833 - val_loss: 0.9108 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.8300 - accuracy: 0.6833 - val_loss: 0.9083 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.8276 - accuracy: 0.6833 - val_loss: 0.9058 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.8252 - accuracy: 0.6833 - val_loss: 0.9033 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.8228 - accuracy: 0.6833 - val_loss: 0.9007 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8205 - accuracy: 0.6833 - val_loss: 0.8983 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.8182 - accuracy: 0.6833 - val_loss: 0.8955 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8158 - accuracy: 0.6833 - val_loss: 0.8930 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.8135 - accuracy: 0.6833 - val_loss: 0.8906 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.8111 - accuracy: 0.6833 - val_loss: 0.8882 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.8088 - accuracy: 0.6833 - val_loss: 0.8858 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7500 - accuracy: 0.78 - 0s 259us/sample - loss: 0.8066 - accuracy: 0.6833 - val_loss: 0.8835 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.8042 - accuracy: 0.6833 - val_loss: 0.8811 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.8019 - accuracy: 0.6833 - val_loss: 0.8789 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7998 - accuracy: 0.6833 - val_loss: 0.8768 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.7974 - accuracy: 0.6833 - val_loss: 0.8741 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.7951 - accuracy: 0.6833 - val_loss: 0.8717 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7929 - accuracy: 0.6833 - val_loss: 0.8692 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.7907 - accuracy: 0.6833 - val_loss: 0.8669 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.7884 - accuracy: 0.6833 - val_loss: 0.8645 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.7863 - accuracy: 0.6833 - val_loss: 0.8623 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.7840 - accuracy: 0.6833 - val_loss: 0.8599 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.7818 - accuracy: 0.6833 - val_loss: 0.8575 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.7797 - accuracy: 0.6833 - val_loss: 0.8555 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7775 - accuracy: 0.6833 - val_loss: 0.8532 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.7754 - accuracy: 0.6833 - val_loss: 0.8506 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.7732 - accuracy: 0.6833 - val_loss: 0.8483 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 186us/sample - loss: 0.7710 - accuracy: 0.6833 - val_loss: 0.8461 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7689 - accuracy: 0.6833 - val_loss: 0.8440 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.7668 - accuracy: 0.6833 - val_loss: 0.8417 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.7647 - accuracy: 0.6833 - val_loss: 0.8393 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.7626 - accuracy: 0.6833 - val_loss: 0.8373 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 243us/sample - loss: 0.7605 - accuracy: 0.6833 - val_loss: 0.8351 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.7584 - accuracy: 0.6833 - val_loss: 0.8328 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7563 - accuracy: 0.6833 - val_loss: 0.8303 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.7543 - accuracy: 0.6833 - val_loss: 0.8282 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 346us/sample - loss: 0.7523 - accuracy: 0.6833 - val_loss: 0.8257 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.7502 - accuracy: 0.6833 - val_loss: 0.8234 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.7482 - accuracy: 0.6833 - val_loss: 0.8212 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.7463 - accuracy: 0.6833 - val_loss: 0.8188 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.7442 - accuracy: 0.6833 - val_loss: 0.8165 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.7422 - accuracy: 0.6833 - val_loss: 0.8144 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.7402 - accuracy: 0.6833 - val_loss: 0.8123 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.7383 - accuracy: 0.6833 - val_loss: 0.8102 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.7363 - accuracy: 0.6833 - val_loss: 0.8082 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.7343 - accuracy: 0.6833 - val_loss: 0.8063 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7324 - accuracy: 0.6833 - val_loss: 0.8043 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.7305 - accuracy: 0.6833 - val_loss: 0.8022 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.7286 - accuracy: 0.6833 - val_loss: 0.7999 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.7266 - accuracy: 0.6917 - val_loss: 0.7978 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.7247 - accuracy: 0.6917 - val_loss: 0.7957 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.7229 - accuracy: 0.6917 - val_loss: 0.7936 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.7210 - accuracy: 0.6917 - val_loss: 0.7914 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.7191 - accuracy: 0.6917 - val_loss: 0.7893 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.7172 - accuracy: 0.6917 - val_loss: 0.7873 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.7154 - accuracy: 0.6917 - val_loss: 0.7851 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.7136 - accuracy: 0.6917 - val_loss: 0.7831 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.7118 - accuracy: 0.6917 - val_loss: 0.7810 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7099 - accuracy: 0.6917 - val_loss: 0.7790 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.7082 - accuracy: 0.6917 - val_loss: 0.7771 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.7064 - accuracy: 0.6917 - val_loss: 0.7750 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.7046 - accuracy: 0.6917 - val_loss: 0.7731 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.7028 - accuracy: 0.6917 - val_loss: 0.7711 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.7011 - accuracy: 0.6917 - val_loss: 0.7690 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6993 - accuracy: 0.6917 - val_loss: 0.7672 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.65 - 0s 293us/sample - loss: 0.6975 - accuracy: 0.6917 - val_loss: 0.7653 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.6959 - accuracy: 0.6917 - val_loss: 0.7633 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 244us/sample - loss: 0.6941 - accuracy: 0.6917 - val_loss: 0.7613 - val_accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.6924 - accuracy: 0.6917 - val_loss: 0.7593 - val_accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.6907 - accuracy: 0.6917 - val_loss: 0.7574 - val_accuracy: 0.6333\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.6890 - accuracy: 0.6917 - val_loss: 0.7555 - val_accuracy: 0.6333\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.6873 - accuracy: 0.6917 - val_loss: 0.7538 - val_accuracy: 0.6333\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6857 - accuracy: 0.6917 - val_loss: 0.7516 - val_accuracy: 0.6333\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6840 - accuracy: 0.6917 - val_loss: 0.7497 - val_accuracy: 0.6333\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.6824 - accuracy: 0.6917 - val_loss: 0.7480 - val_accuracy: 0.6333\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 276us/sample - loss: 0.6808 - accuracy: 0.6917 - val_loss: 0.7460 - val_accuracy: 0.6333\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6791 - accuracy: 0.6917 - val_loss: 0.7443 - val_accuracy: 0.6333\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.6774 - accuracy: 0.6917 - val_loss: 0.7426 - val_accuracy: 0.6333\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.6758 - accuracy: 0.6917 - val_loss: 0.7409 - val_accuracy: 0.6333\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.6742 - accuracy: 0.6917 - val_loss: 0.7393 - val_accuracy: 0.6333\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.6727 - accuracy: 0.7083 - val_loss: 0.7374 - val_accuracy: 0.6333\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.6711 - accuracy: 0.7083 - val_loss: 0.7356 - val_accuracy: 0.6333\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.6695 - accuracy: 0.7083 - val_loss: 0.7338 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.6680 - accuracy: 0.7083 - val_loss: 0.7321 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6664 - accuracy: 0.7083 - val_loss: 0.7304 - val_accuracy: 0.6333\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.6648 - accuracy: 0.7083 - val_loss: 0.7287 - val_accuracy: 0.6333\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6634 - accuracy: 0.7083 - val_loss: 0.7269 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.6618 - accuracy: 0.7083 - val_loss: 0.7254 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.6603 - accuracy: 0.7083 - val_loss: 0.7237 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6588 - accuracy: 0.7083 - val_loss: 0.7220 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.6573 - accuracy: 0.7083 - val_loss: 0.7205 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.6558 - accuracy: 0.7083 - val_loss: 0.7190 - val_accuracy: 0.6333\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6544 - accuracy: 0.7083 - val_loss: 0.7173 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.6529 - accuracy: 0.7083 - val_loss: 0.7159 - val_accuracy: 0.6333\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.6515 - accuracy: 0.7083 - val_loss: 0.7143 - val_accuracy: 0.6333\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.6500 - accuracy: 0.7083 - val_loss: 0.7127 - val_accuracy: 0.6333\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.6486 - accuracy: 0.7167 - val_loss: 0.7110 - val_accuracy: 0.6333\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.6472 - accuracy: 0.7167 - val_loss: 0.7094 - val_accuracy: 0.6333\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 269us/sample - loss: 0.6458 - accuracy: 0.7167 - val_loss: 0.7079 - val_accuracy: 0.6333\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6443 - accuracy: 0.7250 - val_loss: 0.7063 - val_accuracy: 0.6333\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6429 - accuracy: 0.7250 - val_loss: 0.7048 - val_accuracy: 0.6333\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.6415 - accuracy: 0.7333 - val_loss: 0.7032 - val_accuracy: 0.6333\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.6401 - accuracy: 0.7333 - val_loss: 0.7016 - val_accuracy: 0.6333\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 265us/sample - loss: 0.6388 - accuracy: 0.7333 - val_loss: 0.6999 - val_accuracy: 0.6333\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.6374 - accuracy: 0.7333 - val_loss: 0.6984 - val_accuracy: 0.6333\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.6361 - accuracy: 0.7333 - val_loss: 0.6968 - val_accuracy: 0.6333\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.6347 - accuracy: 0.7333 - val_loss: 0.6952 - val_accuracy: 0.6333\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.6334 - accuracy: 0.7333 - val_loss: 0.6938 - val_accuracy: 0.6333\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.6320 - accuracy: 0.7333 - val_loss: 0.6922 - val_accuracy: 0.6333\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.6306 - accuracy: 0.7333 - val_loss: 0.6908 - val_accuracy: 0.6333\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.6294 - accuracy: 0.7333 - val_loss: 0.6893 - val_accuracy: 0.6333\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 0.6280 - accuracy: 0.7333 - val_loss: 0.6877 - val_accuracy: 0.6333\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 171us/sample - loss: 0.6267 - accuracy: 0.7333 - val_loss: 0.6862 - val_accuracy: 0.6333\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6255 - accuracy: 0.7333 - val_loss: 0.6846 - val_accuracy: 0.6333\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6241 - accuracy: 0.7333 - val_loss: 0.6833 - val_accuracy: 0.6333\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.6229 - accuracy: 0.7333 - val_loss: 0.6820 - val_accuracy: 0.6333\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.6216 - accuracy: 0.7333 - val_loss: 0.6804 - val_accuracy: 0.6333\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.6203 - accuracy: 0.7333 - val_loss: 0.6791 - val_accuracy: 0.6333\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.6191 - accuracy: 0.7333 - val_loss: 0.6778 - val_accuracy: 0.6333\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6179 - accuracy: 0.7333 - val_loss: 0.6763 - val_accuracy: 0.6333\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.6166 - accuracy: 0.7333 - val_loss: 0.6749 - val_accuracy: 0.6333\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.6154 - accuracy: 0.7333 - val_loss: 0.6735 - val_accuracy: 0.6333\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.6142 - accuracy: 0.7333 - val_loss: 0.6719 - val_accuracy: 0.6333\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.6129 - accuracy: 0.7333 - val_loss: 0.6707 - val_accuracy: 0.6333\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6117 - accuracy: 0.7333 - val_loss: 0.6694 - val_accuracy: 0.6333\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.6105 - accuracy: 0.7333 - val_loss: 0.6683 - val_accuracy: 0.6333\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.6093 - accuracy: 0.7333 - val_loss: 0.6669 - val_accuracy: 0.6333\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.6082 - accuracy: 0.7333 - val_loss: 0.6657 - val_accuracy: 0.6333\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.6069 - accuracy: 0.7333 - val_loss: 0.6644 - val_accuracy: 0.6333\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6057 - accuracy: 0.7333 - val_loss: 0.6631 - val_accuracy: 0.6333\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.6048 - accuracy: 0.7333 - val_loss: 0.6615 - val_accuracy: 0.6333\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.6034 - accuracy: 0.7333 - val_loss: 0.6605 - val_accuracy: 0.6333\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.6023 - accuracy: 0.7333 - val_loss: 0.6594 - val_accuracy: 0.6333\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.6012 - accuracy: 0.7333 - val_loss: 0.6582 - val_accuracy: 0.6333\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.6000 - accuracy: 0.7333 - val_loss: 0.6571 - val_accuracy: 0.6333\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.5989 - accuracy: 0.7333 - val_loss: 0.6560 - val_accuracy: 0.6333\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.5977 - accuracy: 0.7333 - val_loss: 0.6550 - val_accuracy: 0.6333\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.5967 - accuracy: 0.7333 - val_loss: 0.6537 - val_accuracy: 0.6333\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.5956 - accuracy: 0.7333 - val_loss: 0.6525 - val_accuracy: 0.6333\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.5944 - accuracy: 0.7333 - val_loss: 0.6514 - val_accuracy: 0.6333\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5934 - accuracy: 0.7333 - val_loss: 0.6501 - val_accuracy: 0.6333\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5922 - accuracy: 0.7333 - val_loss: 0.6489 - val_accuracy: 0.6333\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.5911 - accuracy: 0.7333 - val_loss: 0.6478 - val_accuracy: 0.6333\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.5901 - accuracy: 0.7333 - val_loss: 0.6467 - val_accuracy: 0.6333\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.5890 - accuracy: 0.7333 - val_loss: 0.6454 - val_accuracy: 0.6667\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5879 - accuracy: 0.7333 - val_loss: 0.6442 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5869 - accuracy: 0.7333 - val_loss: 0.6429 - val_accuracy: 0.6667\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.5858 - accuracy: 0.7500 - val_loss: 0.6416 - val_accuracy: 0.6667\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.5847 - accuracy: 0.7500 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5838 - accuracy: 0.7500 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5827 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5817 - accuracy: 0.7500 - val_loss: 0.6361 - val_accuracy: 0.6667\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.5807 - accuracy: 0.7500 - val_loss: 0.6349 - val_accuracy: 0.6667\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.5796 - accuracy: 0.7500 - val_loss: 0.6336 - val_accuracy: 0.6667\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.5786 - accuracy: 0.7500 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5776 - accuracy: 0.7500 - val_loss: 0.6315 - val_accuracy: 0.6667\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.5766 - accuracy: 0.7500 - val_loss: 0.6306 - val_accuracy: 0.6667\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5757 - accuracy: 0.7500 - val_loss: 0.6295 - val_accuracy: 0.6667\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5746 - accuracy: 0.7500 - val_loss: 0.6285 - val_accuracy: 0.6667\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5737 - accuracy: 0.7500 - val_loss: 0.6274 - val_accuracy: 0.6667\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.6264 - val_accuracy: 0.6667\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5717 - accuracy: 0.7500 - val_loss: 0.6257 - val_accuracy: 0.6667\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.6245 - val_accuracy: 0.6667\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.6237 - val_accuracy: 0.6667\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5688 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.6667\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.6205 - val_accuracy: 0.6667\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5660 - accuracy: 0.7500 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.5650 - accuracy: 0.7500 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.6172 - val_accuracy: 0.6667\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 271us/sample - loss: 0.5623 - accuracy: 0.7500 - val_loss: 0.6150 - val_accuracy: 0.6667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.5613 - accuracy: 0.7500 - val_loss: 0.6139 - val_accuracy: 0.7000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.5604 - accuracy: 0.7500 - val_loss: 0.6128 - val_accuracy: 0.7000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5595 - accuracy: 0.7500 - val_loss: 0.6117 - val_accuracy: 0.7000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5588 - accuracy: 0.7500 - val_loss: 0.6105 - val_accuracy: 0.7667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.5577 - accuracy: 0.7500 - val_loss: 0.6096 - val_accuracy: 0.7667\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.5568 - accuracy: 0.7500 - val_loss: 0.6089 - val_accuracy: 0.7333\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.5561 - accuracy: 0.7500 - val_loss: 0.6083 - val_accuracy: 0.7000\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5551 - accuracy: 0.7500 - val_loss: 0.6075 - val_accuracy: 0.7000\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5542 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.5533 - accuracy: 0.7500 - val_loss: 0.6053 - val_accuracy: 0.7333\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.5525 - accuracy: 0.7500 - val_loss: 0.6043 - val_accuracy: 0.7667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5516 - accuracy: 0.7500 - val_loss: 0.6034 - val_accuracy: 0.7667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5508 - accuracy: 0.7500 - val_loss: 0.6025 - val_accuracy: 0.7667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 260us/sample - loss: 0.5499 - accuracy: 0.7500 - val_loss: 0.6016 - val_accuracy: 0.7667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5490 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5482 - accuracy: 0.7500 - val_loss: 0.5994 - val_accuracy: 0.7667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5474 - accuracy: 0.7500 - val_loss: 0.5982 - val_accuracy: 0.7667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.5467 - accuracy: 0.7500 - val_loss: 0.5976 - val_accuracy: 0.7667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.5457 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 0.7667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.5449 - accuracy: 0.7500 - val_loss: 0.5955 - val_accuracy: 0.7667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.5440 - accuracy: 0.7500 - val_loss: 0.5946 - val_accuracy: 0.7667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5432 - accuracy: 0.7500 - val_loss: 0.5936 - val_accuracy: 0.7667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.5424 - accuracy: 0.7500 - val_loss: 0.5928 - val_accuracy: 0.7667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.5416 - accuracy: 0.7500 - val_loss: 0.5921 - val_accuracy: 0.7667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.5407 - accuracy: 0.7500 - val_loss: 0.5912 - val_accuracy: 0.7667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.5399 - accuracy: 0.7500 - val_loss: 0.5902 - val_accuracy: 0.7667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5391 - accuracy: 0.7500 - val_loss: 0.5892 - val_accuracy: 0.7667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5383 - accuracy: 0.7500 - val_loss: 0.5882 - val_accuracy: 0.7667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.5376 - accuracy: 0.7500 - val_loss: 0.5872 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.5367 - accuracy: 0.7667 - val_loss: 0.5862 - val_accuracy: 0.7667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.5359 - accuracy: 0.7667 - val_loss: 0.5853 - val_accuracy: 0.7667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5352 - accuracy: 0.7667 - val_loss: 0.5845 - val_accuracy: 0.7667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.5344 - accuracy: 0.7667 - val_loss: 0.5836 - val_accuracy: 0.7667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.5336 - accuracy: 0.7667 - val_loss: 0.5827 - val_accuracy: 0.7667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.5328 - accuracy: 0.7667 - val_loss: 0.5819 - val_accuracy: 0.7667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5321 - accuracy: 0.7667 - val_loss: 0.5810 - val_accuracy: 0.7667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5313 - accuracy: 0.7667 - val_loss: 0.5803 - val_accuracy: 0.7667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5305 - accuracy: 0.7667 - val_loss: 0.5796 - val_accuracy: 0.7667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5298 - accuracy: 0.7667 - val_loss: 0.5789 - val_accuracy: 0.7667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5290 - accuracy: 0.7667 - val_loss: 0.5780 - val_accuracy: 0.7667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.5284 - accuracy: 0.7750 - val_loss: 0.5768 - val_accuracy: 0.7667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.5275 - accuracy: 0.7750 - val_loss: 0.5760 - val_accuracy: 0.7667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.5268 - accuracy: 0.7750 - val_loss: 0.5751 - val_accuracy: 0.7667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.5260 - accuracy: 0.7750 - val_loss: 0.5743 - val_accuracy: 0.7667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.5253 - accuracy: 0.7750 - val_loss: 0.5737 - val_accuracy: 0.7667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.5246 - accuracy: 0.7750 - val_loss: 0.5730 - val_accuracy: 0.7667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 174us/sample - loss: 0.5238 - accuracy: 0.7750 - val_loss: 0.5721 - val_accuracy: 0.7667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.5231 - accuracy: 0.7750 - val_loss: 0.5712 - val_accuracy: 0.7667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5224 - accuracy: 0.7750 - val_loss: 0.5704 - val_accuracy: 0.7667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.5216 - accuracy: 0.7750 - val_loss: 0.5696 - val_accuracy: 0.7667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.5209 - accuracy: 0.7750 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5202 - accuracy: 0.7750 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.5195 - accuracy: 0.7750 - val_loss: 0.5672 - val_accuracy: 0.8000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.5188 - accuracy: 0.7750 - val_loss: 0.5662 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x200f638b948>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=300,validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.013019</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.068555</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.011141</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.066353</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.009182</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.064277</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.007293</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.062186</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.005422</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>1.060051</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.521633</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.569621</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.520944</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.568794</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.520241</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.567954</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.519509</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.567215</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.518783</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.013019  0.400000  1.068555      0.300000\n",
       "1    1.011141  0.416667  1.066353      0.300000\n",
       "2    1.009182  0.433333  1.064277      0.300000\n",
       "3    1.007293  0.458333  1.062186      0.333333\n",
       "4    1.005422  0.475000  1.060051      0.333333\n",
       "..        ...       ...       ...           ...\n",
       "295  0.521633  0.775000  0.569621      0.766667\n",
       "296  0.520944  0.775000  0.568794      0.800000\n",
       "297  0.520241  0.775000  0.567954      0.800000\n",
       "298  0.519509  0.775000  0.567215      0.800000\n",
       "299  0.518783  0.775000  0.566210      0.800000\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x200f66a73c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x200f8e18788>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5662099719047546, 0.8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 1s 5ms/sample - loss: 1.1260 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 1.1218 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 1.1175 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1133 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 1.1101 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 1.1067 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 1.1041 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 1.1013 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 1.0999 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0973 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0959 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0943 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0930 - accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0922 - accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 1.0909 - accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 1.0901 - accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 1.0891 - accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0883 - accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0875 - accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 1.0867 - accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 1.0860 - accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0853 - accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 1.0846 - accuracy: 0.3333\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0842 - accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0834 - accuracy: 0.3333\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 1.0828 - accuracy: 0.3333\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 1.0823 - accuracy: 0.3333\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 1.0816 - accuracy: 0.3333\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 1.0810 - accuracy: 0.3333\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.0804 - accuracy: 0.3333\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 1.0799 - accuracy: 0.3333\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.0792 - accuracy: 0.3333\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 1.0786 - accuracy: 0.3333\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 1.0780 - accuracy: 0.3467\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 1.0774 - accuracy: 0.3533\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 1.0767 - accuracy: 0.3533\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 1.0762 - accuracy: 0.3533\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 1.0754 - accuracy: 0.3533\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.0748 - accuracy: 0.3533\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 1.0741 - accuracy: 0.3533\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 1.0733 - accuracy: 0.3533\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0726 - accuracy: 0.3533\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 1.0720 - accuracy: 0.3533\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 1.0712 - accuracy: 0.3533\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0704 - accuracy: 0.3533\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0696 - accuracy: 0.3533\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0687 - accuracy: 0.3533\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0679 - accuracy: 0.3533\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 1.0670 - accuracy: 0.3533\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 1.0661 - accuracy: 0.3533\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 1.0652 - accuracy: 0.3533\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0642 - accuracy: 0.3533\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0632 - accuracy: 0.3533\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0622 - accuracy: 0.3533\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0611 - accuracy: 0.3533\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0601 - accuracy: 0.3533\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 1.0589 - accuracy: 0.3600\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 1.0578 - accuracy: 0.3600\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 1.0566 - accuracy: 0.3600\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0554 - accuracy: 0.3600\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 1.0541 - accuracy: 0.3600\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0528 - accuracy: 0.3600\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 1.0515 - accuracy: 0.3600\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 1.0501 - accuracy: 0.3600\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0487 - accuracy: 0.3600\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0472 - accuracy: 0.3600\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0458 - accuracy: 0.3600\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 1.0442 - accuracy: 0.3600\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 1.0426 - accuracy: 0.3600\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 1.0411 - accuracy: 0.3600\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 1.0395 - accuracy: 0.3600\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 1.0378 - accuracy: 0.3600\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0360 - accuracy: 0.3600\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 1.0342 - accuracy: 0.3600\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0324 - accuracy: 0.3600\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0306 - accuracy: 0.3600\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0287 - accuracy: 0.3600\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 89us/sample - loss: 1.0267 - accuracy: 0.3600\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 1.0247 - accuracy: 0.3600\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 1.0228 - accuracy: 0.3600\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 1.0207 - accuracy: 0.3600\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0186 - accuracy: 0.3600\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 1.0165 - accuracy: 0.3600\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 1.0145 - accuracy: 0.3600\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 1.0120 - accuracy: 0.3600\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0098 - accuracy: 0.3600\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 1.0075 - accuracy: 0.3600\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 1.0052 - accuracy: 0.3600\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0027 - accuracy: 0.3667\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 1.0002 - accuracy: 0.3667\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.9978 - accuracy: 0.3667\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.9952 - accuracy: 0.3667\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9926 - accuracy: 0.3667\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.9898 - accuracy: 0.3667\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9871 - accuracy: 0.3667\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9843 - accuracy: 0.3667\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9815 - accuracy: 0.3667\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9788 - accuracy: 0.3667\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.9758 - accuracy: 0.3667\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9729 - accuracy: 0.3667\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9702 - accuracy: 0.3667\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.9672 - accuracy: 0.3600\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9642 - accuracy: 0.3667\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9613 - accuracy: 0.3667\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9584 - accuracy: 0.3667\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9553 - accuracy: 0.3667\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.9523 - accuracy: 0.3667\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.9493 - accuracy: 0.3667\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9463 - accuracy: 0.3667\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.9432 - accuracy: 0.3667\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.9401 - accuracy: 0.3667\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.9371 - accuracy: 0.3667\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.9340 - accuracy: 0.3667\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.9309 - accuracy: 0.3667\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9278 - accuracy: 0.3667\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.9247 - accuracy: 0.3667\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9216 - accuracy: 0.3667\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9185 - accuracy: 0.3667\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9153 - accuracy: 0.3667\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.9122 - accuracy: 0.3667\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.9091 - accuracy: 0.3667\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.9060 - accuracy: 0.3667\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.9028 - accuracy: 0.3667\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8997 - accuracy: 0.3667\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8965 - accuracy: 0.3667\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8934 - accuracy: 0.3667\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8902 - accuracy: 0.3667\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.8870 - accuracy: 0.3667\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.40 - 0s 127us/sample - loss: 0.8838 - accuracy: 0.3667\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8808 - accuracy: 0.3667\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8776 - accuracy: 0.3733\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8744 - accuracy: 0.3667\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.8713 - accuracy: 0.3667\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8680 - accuracy: 0.3667\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.8649 - accuracy: 0.3667\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8617 - accuracy: 0.3667\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.8586 - accuracy: 0.3667\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.8553 - accuracy: 0.3667\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.8522 - accuracy: 0.3933\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8489 - accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.8457 - accuracy: 0.6200\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.8426 - accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8394 - accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.8362 - accuracy: 0.6467\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8330 - accuracy: 0.6600\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.8299 - accuracy: 0.6667\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8267 - accuracy: 0.6733\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8235 - accuracy: 0.6733\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8204 - accuracy: 0.6733\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.8173 - accuracy: 0.6733\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8141 - accuracy: 0.6800\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.8109 - accuracy: 0.6800\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8078 - accuracy: 0.6867\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8046 - accuracy: 0.6933\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.8015 - accuracy: 0.6933\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7983 - accuracy: 0.7000\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.7952 - accuracy: 0.7000\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.7921 - accuracy: 0.7067\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.7889 - accuracy: 0.7067\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7859 - accuracy: 0.7133\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.7827 - accuracy: 0.7133\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7796 - accuracy: 0.7133\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.7766 - accuracy: 0.7133\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.7735 - accuracy: 0.7133\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7704 - accuracy: 0.7133\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.7673 - accuracy: 0.7133\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.7642 - accuracy: 0.7133\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7613 - accuracy: 0.7133\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7583 - accuracy: 0.7133\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.7551 - accuracy: 0.7133\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.7521 - accuracy: 0.7133\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7491 - accuracy: 0.7133\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.7461 - accuracy: 0.7133\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7432 - accuracy: 0.7133\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.7401 - accuracy: 0.7133\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 0.7371 - accuracy: 0.7133\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7342 - accuracy: 0.7133\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.7313 - accuracy: 0.7133\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.7283 - accuracy: 0.7200\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7254 - accuracy: 0.7200\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.7225 - accuracy: 0.7200\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7196 - accuracy: 0.7200\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.7168 - accuracy: 0.7200\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7140 - accuracy: 0.7200\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7111 - accuracy: 0.7200\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.7082 - accuracy: 0.7200\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.7055 - accuracy: 0.7200\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 121us/sample - loss: 0.7027 - accuracy: 0.7200\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7002 - accuracy: 0.7267\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.6972 - accuracy: 0.7333\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6945 - accuracy: 0.7333\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6918 - accuracy: 0.7333\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.6892 - accuracy: 0.7333\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.6865 - accuracy: 0.7333\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.6840 - accuracy: 0.7333\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.6812 - accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.6787 - accuracy: 0.7333\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.6761 - accuracy: 0.7333\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.6735 - accuracy: 0.7400\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.6710 - accuracy: 0.7400\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.6685 - accuracy: 0.7400\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.6661 - accuracy: 0.7400\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6636 - accuracy: 0.7400\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6611 - accuracy: 0.7467\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6588 - accuracy: 0.7467\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.6564 - accuracy: 0.7467\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.6539 - accuracy: 0.7467\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6516 - accuracy: 0.7467\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6494 - accuracy: 0.7467\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.6470 - accuracy: 0.7467\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.6448 - accuracy: 0.7467\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.6425 - accuracy: 0.7467\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6404 - accuracy: 0.7533\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6381 - accuracy: 0.7600\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.6360 - accuracy: 0.7600\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.6340 - accuracy: 0.7733\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.6319 - accuracy: 0.7867\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6300 - accuracy: 0.7867\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.6280 - accuracy: 0.7867\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.6258 - accuracy: 0.7867\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6239 - accuracy: 0.7867\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6220 - accuracy: 0.7867\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.6202 - accuracy: 0.7933\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.6184 - accuracy: 0.7933\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.6166 - accuracy: 0.7933\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.6148 - accuracy: 0.8133\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.6130 - accuracy: 0.8133\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.6113 - accuracy: 0.8133\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.6096 - accuracy: 0.8133\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.6079 - accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.6063 - accuracy: 0.8133\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6046 - accuracy: 0.8133\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6029 - accuracy: 0.8133\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6013 - accuracy: 0.8133\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.5997 - accuracy: 0.8133\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.5980 - accuracy: 0.8133\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5964 - accuracy: 0.8133\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5949 - accuracy: 0.8133\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.5934 - accuracy: 0.8200\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5918 - accuracy: 0.8133\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5903 - accuracy: 0.8133\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.5887 - accuracy: 0.8133\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5873 - accuracy: 0.8133\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5858 - accuracy: 0.8133\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5842 - accuracy: 0.8133\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5828 - accuracy: 0.8133\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5814 - accuracy: 0.8133\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.5800 - accuracy: 0.8200\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5785 - accuracy: 0.8200\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.5771 - accuracy: 0.8200\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.5757 - accuracy: 0.8200\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5742 - accuracy: 0.8200\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5729 - accuracy: 0.8200\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5715 - accuracy: 0.8200\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5700 - accuracy: 0.8200\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5687 - accuracy: 0.8200\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.5674 - accuracy: 0.8200\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.5661 - accuracy: 0.8200\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5648 - accuracy: 0.8200\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5636 - accuracy: 0.8200\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.5621 - accuracy: 0.8200\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5609 - accuracy: 0.8200\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5596 - accuracy: 0.8200\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5582 - accuracy: 0.8200\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5570 - accuracy: 0.8200\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.5558 - accuracy: 0.8200\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 118us/sample - loss: 0.5545 - accuracy: 0.8200\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.5533 - accuracy: 0.8200\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.5521 - accuracy: 0.8267\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5508 - accuracy: 0.8267\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5496 - accuracy: 0.8267\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5485 - accuracy: 0.8267\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.5472 - accuracy: 0.8267\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.5461 - accuracy: 0.8267\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.5451 - accuracy: 0.8200\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.5438 - accuracy: 0.8200\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.5426 - accuracy: 0.8267\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5414 - accuracy: 0.8267\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.5404 - accuracy: 0.8267\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.5392 - accuracy: 0.8267\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5382 - accuracy: 0.8200\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.5370 - accuracy: 0.8267\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5360 - accuracy: 0.8333\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.5348 - accuracy: 0.8333\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5337 - accuracy: 0.8333\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.5326 - accuracy: 0.8333\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5315 - accuracy: 0.8333\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5305 - accuracy: 0.8333\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.5294 - accuracy: 0.8333\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5283 - accuracy: 0.8333\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5274 - accuracy: 0.8333\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5263 - accuracy: 0.8333\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5252 - accuracy: 0.8333\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.5242 - accuracy: 0.8333\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.5232 - accuracy: 0.8267\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.5221 - accuracy: 0.8333\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5211 - accuracy: 0.8333\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5201 - accuracy: 0.8333\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.5192 - accuracy: 0.8333\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.5181 - accuracy: 0.8267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x200f9ea8688>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler1.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('iris_scaler1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\"sepal_length\":5.1,\"sepal_width\":3.5,\"petal_length\":1.4,\"petal_width\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FOR DEPLOYMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "flower_model = load_model('final_iris_model1.h5')\n",
    "flower_scaler = joblib.load('iris_scaler1.pkl')\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
